{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project name: AMAGroup test\n",
    "\n",
    "Description: This notebook file aims to produce annotation text files for each image in the dataset according to the format that YOLOv7 accepts\n",
    "\n",
    "Author: Ali Saghafi\n",
    "\n",
    "Date: 31/10/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(bbox,coor):\n",
    "    normalized_bbox = [\n",
    "        bbox[0] / coor[0],  # Normalize centre x\n",
    "        bbox[1] / coor[1],  # Normalize centre y\n",
    "        bbox[2] / coor[0],  # Normalize box width\n",
    "        bbox[3] / coor[1]   # Normalize box height\n",
    "    ]\n",
    "    return normalized_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __location__ = os.path.realpath(os.path.join(\n",
    "        os.getcwd(), os.path.dirname(__file__)))\n",
    "except(NameError):\n",
    "    __location__ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = __location__+\"\\\\material\"\n",
    "with open(file_path+\"\\\\instances_val2017.json\", 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = json_data['images']\n",
    "annotation_list = json_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary format {image_id:image_name} \n",
    "id_nam_dict = {}\n",
    "for item in image_list:\n",
    "    if 'file_name' in item and 'id' in item:\n",
    "        key_new = item['id']\n",
    "        value_new = item['file_name']\n",
    "        id_nam_dict[key_new] = value_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording width and height for later normalization\n",
    "norm_dict = {}\n",
    "for item in image_list:\n",
    "    if 'width' in item and 'height' in item and 'id' in item:\n",
    "        key_new = item['id']\n",
    "        value_new = [item['width'], item['height']]\n",
    "        norm_dict[key_new] = value_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The annot_dict is a dictionary which amalgamate all areas and corresponding bounding boxes of each image together\n",
    "annot_dict = {}\n",
    "for id, _ in id_nam_dict.items():\n",
    "    for item in annotation_list:\n",
    "                    \n",
    "        if item['image_id'] == id:\n",
    "            if id not in annot_dict:\n",
    "                annot_dict[id] = {'areas': [item['area']], 'bboxes': [item['bbox']]}\n",
    "            else:\n",
    "                annot_dict[id]['areas'].append(item['area'])\n",
    "                annot_dict[id]['bboxes'].append(item['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract the largest and smallest area and corresponding bonding boxes\n",
    "result_dict = {}\n",
    "\n",
    "for id_key, values in annot_dict.items():\n",
    "    area_data = values['areas']\n",
    "    bbox_data = values['bboxes']\n",
    "\n",
    "    areas_with_index = list(enumerate(area_data))  # Create a list of tuples (index, area)\n",
    "    areas_with_index.sort(key=lambda x: x[1])      # Sort the list based on area\n",
    "\n",
    "    largest_area_index = areas_with_index[-1][0]\n",
    "    smallest_area_index = areas_with_index[0][0]\n",
    "\n",
    "    # bounding box normalization\n",
    "    coor = norm_dict[id_key]\n",
    "    smallest_norm = normalize_coordinates(bbox_data[smallest_area_index], coor)\n",
    "    largest_norm = normalize_coordinates(bbox_data[largest_area_index],coor)\n",
    "\n",
    "    # 0 for the smallest class\n",
    "    # 1 for the largest class \n",
    "    result_dict[id_key] = {\n",
    "        0: {'bbox': smallest_norm},\n",
    "        1: {'bbox': largest_norm}\n",
    "    }\n",
    "\n",
    "#print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making corresponding .txt annotation file for each image in the dataset\n",
    "annot_path = __location__ + \"\\\\Dataset\\\\labels\\\\\"\n",
    "for id,name in id_nam_dict.items():\n",
    "    if id in result_dict.keys():\n",
    "        temp = result_dict[id]\n",
    "        file_name = os.path.splitext(name)[0]\n",
    "        with open(f\"{annot_path+file_name}.txt\", \"w\") as file:\n",
    "            for key, value in temp.items():\n",
    "                bbox_values = value['bbox']\n",
    "                #bbox_str = ', '.join(str(coord) for coord in bbox_values)\n",
    "                #file.write(f\"{key} {bbox_str}\\n\")\n",
    "                file.write(f\"{key} \")\n",
    "                for value in bbox_values:\n",
    "                    file.write(str(value) + ' ')\n",
    "                file.write(\"\\n\")  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
